lerna.akka.entityreplication {

  // How long wait before giving up entity recovery.
  // Entity recovery requires a snapshot, and failure fetching it will cause this timeout.
  // If timed out, entity recovery will be retried.
  recovery-entity-timeout = 10s

  raft {
    // The time it takes to start electing a new leader after the heartbeat is no longer received from the leader.
    election-timeout = 750 ms

    // The interval between leaders sending heartbeats to their followers
    heartbeat-interval = 100 ms

    // A role to identify the nodes to place replicas on
    // The number of roles is the number of replicas. It is recommended to set up at least three roles.
    multi-raft-roles = ["replica-group-1", "replica-group-2", "replica-group-3"]

    // Number of shards per single multi-raft-role used by only typed APIs.
    // This value must be the same for all nodes in the cluster
    // and must not be changed after starting to use.
    // Changing this value will cause data inconsistency.
    number-of-shards = 100

    // Maximum number of entries which AppendEntries contains.
    // The too large size will cause message serialization failure.
    max-append-entries-size = 16

    // The maximum number of AppendEnteis that will be sent at once at every heartbeat-interval.
    max-append-entries-batch-size = 10

    // log compaction settings
    compaction {

      // Time interval to check the size of the log and check if a snapshotting is needed to be taken
      log-size-check-interval = 10s

      // Threshold for saving snapshots and compaction of the log.
      // If this value is too large, your application will use a lot of memory and you may get an OutOfMemoryError.
      // If this value is too small, it compaction may occur frequently and overload the application and the data store.
      log-size-threshold = 50000

      // Preserving log entries from log reduction to avoid log replication failure.
      // If more number of logs than this value cannot be synchronized, the raft member will be unavailable.
      // This value should be less than `log-size-threshold` and greater than 0. Otherwise, instantiating RaftSettings will fail.
      preserve-log-size = 10000

      // Time to keep a cache of snapshots in memory
      snapshot-cache-time-to-live = 10s
    }

    // snapshot synchronization settings
    snapshot-sync {

      // Number of snapshots of entities that are copied in parallel
      snapshot-copying-parallelism = 10

      // Time to abort operations related to persistence
      persistence-operation-timeout = 10s

      // Maximum size of a snapshot batch copied from leader's snapshot store to local snapshot store
      // Note:
      // If the event that updated the snapshots contains more than this batch size of entityId,
      // only the snapshots the single event indicates will be copied over this limit.
      // Copying snapshot should be executed atomically per event.
      max-snapshot-batch-size = 1000
    }

    // Entity snapshot store settings
    // All entity snapshot histries are persisted for data recovery.
    entity-snapshot-store {

      // Frequency of taking snapshot of entity snapshot.
      // By taking snapshot, optimizing recovery times of an Entity.
      // Increasing this value increases snapshot writing, decreasing it increases recovery times.
      snapshot-every = 1
    }

    sharding = ${akka.cluster.sharding} {
      // Maximum number of messages that are buffered by a ShardRegion actor.
      // Make it smaller than the default value to discard messages that are too old.
      buffer-size = 1000
    }

    // Raft actors will start automatically after initialization of ClusterReplication.
    // This feature will be enabled only if you will use typed ClusterReplication.
    raft-actor-auto-start {
      // Frequency at which a batch of Raft actors will start
      frequency = 3s
      // The number of Raft actors to be started at a specified interval
      number-of-actors = 5
      // ClusterReplication retries start requests with this interval if it does not receive replies.
      retry-interval = 5s
    }

    // data persistent settings
    persistence {
      // Absolute path to the journal plugin configuration entry.
      // The journal will be stored events which related to Raft.
      journal.plugin = ""

      // Additional settings for persistence plugin
      // These settings are implicitly added to journal-plugin settings to write events related to Raft
      journal-plugin-additional {

        // Note: Please do not change settings below as it is for internal use
        event-adapters {
          akka-entity-replication-raft-event-adapter = "lerna.akka.entityreplication.raft.persistence.RaftEventAdapter"
        }
        event-adapter-bindings {
          "lerna.akka.entityreplication.raft.RaftActor$CompactionCompleted" = akka-entity-replication-raft-event-adapter
          "lerna.akka.entityreplication.raft.snapshot.sync.SnapshotSyncManager$SnapshotCopied" = akka-entity-replication-raft-event-adapter
        }
      }

      // Absolute path to the snapshot store plugin configuration entry.
      // The snapshot store will be stored state which related to Raft.
      snapshot-store.plugin = ""

      // Absolute path to the query plugin configuration entry.
      // Snapshot synchronization reads events that related to Raft.
      query.plugin = ""
    }

  }

  raft.eventsourced {

    // Interval in which Raft Leader checks its committed log entries
    //
    // When new committed log entries are available, the leader sends these new entries to event-sourcing store(a.k.a. CommitLogStore).
    // This interval should be larger enough than network latencies since CommitLogStore might run on another node not running the leader.
    // If this interval is smaller than such latencies, the leader sends the same entry multiple times, which causes network resource inefficiency.
    committed-log-entries-check-interval = 100ms

    // Maximum number of entries AppendCommittedEntries contains.
    // The default value is the same as `raft.max-append-entries-size`.
    // A too-large value might cause message serialization failure.
    max-append-committed-entries-size = ${lerna.akka.entityreplication.raft.max-append-entries-size}

    // Maximum number of AppendCommittedEntries to send at once at every `committed-log-entries-check-interval`.
    // The default value is the same as `raft.max-append-entries-batch-size`.
    // If there are many not-persisted committed entries,
    //  * A too-large value might cause temporary network overload
    //  * A too-small value might cause event-sourcing to take more time to catch up on the latest.
    max-append-committed-entries-batch-size = ${lerna.akka.entityreplication.raft.max-append-entries-batch-size}

    persistence {
      // Absolute path to the journal plugin configuration entry.
      // The journal stores Raft-committed events.
      journal.plugin = ""

      // Absolute path to the snapshot-store plugin configuration entry.
      // The snapshot-store stores a state (snapshot) built from Raft-committed events.
      snapshot-store.plugin = ""

      // Snapshot after this number of events.
      snapshot-every = 1000

      // Enables event deletion of event-sourcing stores (a.k.a CommitLogStore)
      //
      // An event-sourcing store deletes old events when it successfully saves a snapshot if this setting is on.
      //
      // WARNING:
      //   akka-entity-replication only supports Akka Persistence Cassandra since the deletion relies on a tagged-event
      //   table (`akka.tag_views`) being split from an event table (`akka.messages`). Don't use a persistence plugin
      //   that shares such tables if this setting is on since it would result in that journal queries cannot subscribe
      //   to tagged events via the event-sourcing feature.
      //
      // WARNING:
      //   Don't use the optional snapshots feature (`snapshot-is-optional = true`) of a snapshot plugin if this setting
      //   is on since it would make an event-sourcing store an inconsistent sate if a snapshot load fails.
      delete-old-events = off

      // Enables snapshot deletion of event-sourcing stores (a.k.a CommitLogStore)
      //
      // An event-sourcing store deletes old snapshots when it successfully saves a snapshot if this setting is on.
      delete-old-snapshots = off

      // The relative sequence number for determining old events and snapshots to be deleted.
      //
      // Event-sourcing stores delete old events and/or snapshots that have the following sequence numbers:
      //   * For events: `SaveSnapshotSuccess.meta.sequenceNr - delete-before-relative-sequence-nr`
      //   * For snapshots: `SaveSnapshotSuccess.meta.sequenceNr - 1 - delete-before-relative-sequence-nr`
      //
      // Using values higher than or equal to `snapshot-every` is a good starting point. It's because snapshot read and
      // write queries can have different consistency levels, resulting in the read query not reading the latestsnapshot
      // in some cases. Using 0 is possible if the snapshot read query always reads the latest snapshot.
      delete-before-relative-sequence-nr = 1000
    }
  }
}

# Serializer settings for akka-entity-replication messages
akka.actor {
  serialization-identifiers {
    "lerna.akka.entityreplication.protobuf.ClusterReplicationSerializer" = 1188094126
  }
  serializers {
    akka-entity-replication = "lerna.akka.entityreplication.protobuf.ClusterReplicationSerializer"
  }
  serialization-bindings {
    "lerna.akka.entityreplication.ClusterReplicationSerializable" = akka-entity-replication
  }
}
